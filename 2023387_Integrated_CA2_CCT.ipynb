{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa17add7",
   "metadata": {},
   "source": [
    "# Integrated CA2\n",
    "## BigData Processing\n",
    "### Hadoop / PySpark \n",
    "\n",
    "\n",
    "Commands to be include in the Linux Terminal in order to start Hadoop and PySpark\n",
    "\n",
    "$start-dfs.sh\n",
    "\n",
    "$start-yarn.sh\n",
    "\n",
    "$pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "507c91fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating required modules\n",
    "from pyspark.sql import SparkSession  # Essential for Spark operations\n",
    "from pyspark.sql.functions import udf  # User Defined Functions\n",
    "from pyspark.sql.types import StringType  # Data type for string operations\n",
    "import re  # Regular expressions library\n",
    "\n",
    "# Handling warnings\n",
    "import warnings  # Importing warnings library\n",
    "warnings.filterwarnings(\"ignore\")  # Suppress all warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcf9c3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/20 08:36:33 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Setting up the Spark Session\n",
    "spark = SparkSession.builder.appName(\"EmailDataPrep\").getOrCreate()\n",
    "\n",
    "# Reading the data\n",
    "df = spark.read.csv(\"hdfs:///user1/ProjectTweets.csv\", header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c9d634",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) / Data Inspection\n",
    "This section focuses on Exploratory Data Analysis (EDA) and data inspection using PySpark, a tool for handling big data. The aim is to understand the data better by performing initial checks and summaries. \n",
    "\n",
    "Through these steps, the data is initially assessed to guide further detailed analysis and decision-making for cleaning, transforming, and analyzing the data effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ff35076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:45 PDT 2009|NO_QUERY|_TheSpecialOne_|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D|\n",
      "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "|  1|1467810672|        Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|                                                                                               is upset that he ...|\n",
      "|  2|1467810917|        Mon Apr 06 22:19:...|NO_QUERY|       mattycus|                                                                                               @Kenichan I dived...|\n",
      "|  3|1467811184|        Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|                                                                                               my whole body fee...|\n",
      "|  4|1467811193|        Mon Apr 06 22:19:...|NO_QUERY|         Karoli|                                                                                               @nationwideclass ...|\n",
      "|  5|1467811372|        Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|                                                                                               @Kwesidei not the...|\n",
      "|  6|1467811592|        Mon Apr 06 22:20:...|NO_QUERY|        mybirch|                                                                                                        Need a hug |\n",
      "|  7|1467811594|        Mon Apr 06 22:20:...|NO_QUERY|           coZZ|                                                                                               @LOLTrish hey  lo...|\n",
      "|  8|1467811795|        Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|                                                                                               @Tatiana_K nope t...|\n",
      "|  9|1467812025|        Mon Apr 06 22:20:...|NO_QUERY|        mimismo|                                                                                               @twittera que me ...|\n",
      "| 10|1467812416|        Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|                                                                                               spring break in p...|\n",
      "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview the initial rows of the DataFrame\n",
    "df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3704ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
